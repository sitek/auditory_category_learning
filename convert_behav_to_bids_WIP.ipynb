{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "090e4732-3b4e-4e93-8d27-57360732cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a2f1660-d9c6-4033-89ae-09287aac25ab",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLT02\n",
      "file list:  ['/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT02_tone_learning_16-tone_jitter-fb_fmri_2022_Mar_28_1901.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT02_tone_learning_16-tone_jitter-fb_fmri_2022_Mar_28_1913.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT02_tone_learning_16-tone_jitter-fb_fmri_2022_Mar_28_1922.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT02_tone_learning_16-tone_jitter-fb_fmri_2022_Mar_28_1931.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT02_tone_learning_16-tone_jitter-fb_fmri_2022_Mar_28_1941.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT02_tone_learning_16-tone_jitter-fb_fmri_2022_Mar_28_1950.csv']\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT02_tone_learning_16-tone_jitter-fb_fmri_2022_Mar_28_1901.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT02/func/sub-FLT02_task-tonecat_run-01_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT02_tone_learning_16-tone_jitter-fb_fmri_2022_Mar_28_1913.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT02/func/sub-FLT02_task-tonecat_run-02_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT02_tone_learning_16-tone_jitter-fb_fmri_2022_Mar_28_1922.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT02/func/sub-FLT02_task-tonecat_run-03_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT02_tone_learning_16-tone_jitter-fb_fmri_2022_Mar_28_1931.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT02/func/sub-FLT02_task-tonecat_run-04_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT02_tone_learning_16-tone_jitter-fb_fmri_2022_Mar_28_1941.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT02/func/sub-FLT02_task-tonecat_run-05_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT02_tone_learning_16-tone_jitter-fb_fmri_2022_Mar_28_1950.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT02/func/sub-FLT02_task-tonecat_run-06_events.tsv\n",
      "FLT03\n",
      "file list:  ['/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1833.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1845.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1854.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1904.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1914.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1923.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1933.csv']\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1833.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT03/func/sub-FLT03_task-tonecat_run-01_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1845.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT03/func/sub-FLT03_task-tonecat_run-02_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1854.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT03/func/sub-FLT03_task-tonecat_run-03_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1904.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT03/func/sub-FLT03_task-tonecat_run-04_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1914.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT03/func/sub-FLT03_task-tonecat_run-05_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1923.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT03/func/sub-FLT03_task-tonecat_run-06_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT03_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_06_1933.csv\n",
      "too few trials â€“ incomplete run. Skipping\n",
      "FLT05\n",
      "file list:  ['/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT05_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_20_1528.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT05_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_20_1539.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT05_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_20_1549.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT05_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_20_1559.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT05_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_20_1610.csv', '/bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT05_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_20_1618.csv']\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT05_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_20_1528.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT05/func/sub-FLT05_task-tonecat_run-01_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT05_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_20_1539.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT05/func/sub-FLT05_task-tonecat_run-02_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT05_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_20_1549.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT05/func/sub-FLT05_task-tonecat_run-03_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT05_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_20_1559.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT05/func/sub-FLT05_task-tonecat_run-04_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT05_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_20_1610.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT05/func/sub-FLT05_task-tonecat_run-05_events.tsv\n",
      "converting  /bgfs/bchandrasekaran/krs228/data/FLT/sourcedata/behav_files/CHA-IBR/01-ToneLearning/sub-FLT05_tone_learning_16-tone_jitter-fb_fmri_2022_Apr_20_1618.csv\n",
      "saved output to  /bgfs/bchandrasekaran/krs228/data/FLT/data_bids_noIntendedFor/sub-FLT05/func/sub-FLT05_task-tonecat_run-06_events.tsv\n"
     ]
    }
   ],
   "source": [
    "task_id = 'ToneLearning'\n",
    "\n",
    "project_dir = os.path.abspath('/bgfs/bchandrasekaran/krs228/data/FLT/')\n",
    "behav_dir   = os.path.join(project_dir, 'sourcedata', 'behav_files', 'CHA-IBR/')\n",
    "bids_dir    = os.path.join(project_dir, 'data_bids_noIntendedFor')\n",
    "#project_dir = os.path.join('/Users/krs228', 'data', 'FLT')\n",
    "#behav_dir = os.path.join('/Users/krs228/','OneDrive - University of Pittsburgh/','CHA-IBR/')\n",
    "\n",
    "# bids task names\n",
    "bids_task_list = ['tonecat', 'stgrid']\n",
    "\n",
    "#subject_list = ['FLT01', 'FLT04', 'FLT06', 'FLT07',  \n",
    "                 # \n",
    "#                'FLT08', 'FLT09', 'FLT10', 'FLT11', 'FLT12', 'FLT13'] # \n",
    "subject_list = ['FLT02', 'FLT03', 'FLT05', ]\n",
    "\n",
    "for subject_id in subject_list:\n",
    "    print(subject_id)\n",
    "\n",
    "    file_list = sorted(glob(behav_dir + '/*%s*/sub-%s*.csv'%(task_id, subject_id)))\n",
    "    #file_list = [sorted(glob(behav_dir + '/*%s*/sub-%s*.csv'%(task_id, subject_id)))[0]]\n",
    "    print('file list: ', file_list)\n",
    "    \n",
    "    # define initial BOLD acquisition time before task begins during silent gap\n",
    "    first_acq = 2\n",
    "\n",
    "\n",
    "\n",
    "    ''' ToneLearning task '''\n",
    "    if 'ToneLearning' in task_id:\n",
    "        # in this task, stimuli start 0.5 s after the silent gap starts\n",
    "        stim_delay = 0.5\n",
    "\n",
    "        # define the time before the first stimulus starts\n",
    "        first_stim_delay = first_acq + stim_delay\n",
    "        \n",
    "        run_i = 1\n",
    "        for rx, filename in enumerate(file_list):\n",
    "            #try:\n",
    "            print('converting ', filename)\n",
    "            fpath = os.path.join(behav_dir, filename)\n",
    "            df = pd.read_csv(fpath)\n",
    "\n",
    "            # create a temp dataframe of only trials where sounds were presented\n",
    "            trial_df = df[df.corrAns>0]\n",
    "\n",
    "            if len(trial_df)<30:\n",
    "                print('too few trials â€“ incomplete run. Skipping')\n",
    "            else:\n",
    "                ''' Stimulus dataframe '''\n",
    "                # set up stimulus dataframe\n",
    "                stim_df = pd.DataFrame(columns=['onset', \n",
    "                                                'duration', \n",
    "                                                'trial_type',\n",
    "                                                'stim_file'])\n",
    "\n",
    "                # define onset time (relative to the first stimulus presentation)\n",
    "                stim_df.onset = trial_df['sound_1.started'] - (trial_df['sound_1.started'].iloc[0]-first_stim_delay)\n",
    "\n",
    "                # define duration\n",
    "                # stim_df.duration = trial_df['sound_1.stopped'].astype(np.float16) - trial_df['sound_1.started'].astype(np.float16)\n",
    "                stim_df.duration = 0.3\n",
    "\n",
    "                # define stimulus type (based on sound file â€“ HARDCODED)\n",
    "                stim_df.trial_type = 'sound_'+trial_df.soundfile.str[8:14]\n",
    "                '''\n",
    "                stim_df.trial_type[trial_df.soundfile=='stimuli/di1-aN_48000Hz_pol2_S15filt.wav'] = 'di1-aN'\n",
    "                '''\n",
    "\n",
    "                # define stimulus soundfile\n",
    "                stim_df.stim_file = trial_df.soundfile\n",
    "\n",
    "                ''' Response dataframe '''\n",
    "                # set up response dataframe\n",
    "                resp_df = pd.DataFrame(columns=['onset', \n",
    "                                                'duration',\n",
    "                                                'response_time', \n",
    "                                                'correct_key',\n",
    "                                                'trial_type'])\n",
    "\n",
    "                # define onset time (relative to the first stimulus presentation)\n",
    "                resp_df.onset = trial_df['sound_1.started'] + trial_df['key_resp.rt']  - (trial_df['sound_1.started'].iloc[0]-first_stim_delay)\n",
    "\n",
    "                # define duration (arbitrary)\n",
    "                resp_df.duration = 0.5\n",
    "\n",
    "                resp_df.response_time = trial_df['key_resp.rt']        \n",
    "                resp_df.correct_key = trial_df['corrAns']\n",
    "                resp_df.trial_type = 'resp_'+trial_df['key_resp.keys']\n",
    "\n",
    "                ''' Feedback dataframe '''\n",
    "                # set up feedback dataframe\n",
    "                fb_df = pd.DataFrame(columns=['onset',\n",
    "                                                'duration', \n",
    "                                                'trial_type'])        \n",
    "\n",
    "                # define onset time (relative to the first stimulus presentation)\n",
    "                fb_df.onset = trial_df['text_2.started'] - (trial_df['sound_1.started'].iloc[0]-first_stim_delay)\n",
    "\n",
    "                # feedback is visible from the onset of text_2 to the onset of jitter_cross_post_fb\n",
    "                fb_df.duration = trial_df['jitter_cross_post_fb.started'] - trial_df['text_2.started']\n",
    "\n",
    "                # define feedback presented\n",
    "                fb_df['trial_type'] = np.where(trial_df['key_resp.corr']==1, 'fb_correct', \n",
    "                                                (np.where(trial_df.corrAns==0, 'none', 'fb_wrong')))\n",
    "\n",
    "                ''' combine all three dataframes '''\n",
    "                bids_df = pd.concat([stim_df, resp_df, fb_df], \n",
    "                                    axis=0, join='outer', ignore_index=True)\n",
    "                bids_df.sort_values(by=['onset'], ignore_index=True,\n",
    "                                    inplace=True)\n",
    "\n",
    "                # save to output path\n",
    "                out_fpath = os.path.join(bids_dir,\n",
    "                                         'sub-%s'%subject_id, 'func',\n",
    "                                         'sub-%s_task-%s_run-%02d_events.tsv'%(subject_id, bids_task_list[0], run_i))\n",
    "\n",
    "                bids_df.to_csv(out_fpath, sep='\\t')\n",
    "                print('saved output to ', out_fpath)\n",
    "                run_i += 1\n",
    "           # except:\n",
    "           #     print('could not process this csv file')\n",
    "           #     print(df.head)\n",
    "           #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6516810a-b734-4230-a420-ea790241a8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>stim_file</th>\n",
       "      <th>response_time</th>\n",
       "      <th>correct_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>sound_di1-iN</td>\n",
       "      <td>stimuli/di1-iN_48000Hz_pol2_S15filt.wav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.622022</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>resp_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.122022</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.079869</td>\n",
       "      <td>0.749823</td>\n",
       "      <td>fb_correct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.494255</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>sound_di4-hN</td>\n",
       "      <td>stimuli/di4-hN_48000Hz_pol2_S15filt.wav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.211985</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>resp_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717730</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>351.160549</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>resp_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.352762</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>353.188481</td>\n",
       "      <td>0.765435</td>\n",
       "      <td>fb_correct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>355.819401</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>sound_di3-iN</td>\n",
       "      <td>stimuli/di3-iN_48000Hz_pol2_S15filt.wav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>357.060995</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>resp_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.241594</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>360.098533</td>\n",
       "      <td>0.765511</td>\n",
       "      <td>fb_correct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          onset  duration    trial_type  \\\n",
       "0      2.500000  0.300000  sound_di1-iN   \n",
       "1      3.622022  0.100000        resp_7   \n",
       "2      6.079869  0.749823    fb_correct   \n",
       "3      8.494255  0.300000  sound_di4-hN   \n",
       "4      9.211985  0.100000        resp_2   \n",
       "..          ...       ...           ...   \n",
       "139  351.160549  0.100000        resp_1   \n",
       "140  353.188481  0.765435    fb_correct   \n",
       "141  355.819401  0.300000  sound_di3-iN   \n",
       "142  357.060995  0.100000        resp_1   \n",
       "143  360.098533  0.765511    fb_correct   \n",
       "\n",
       "                                   stim_file  response_time  correct_key  \n",
       "0    stimuli/di1-iN_48000Hz_pol2_S15filt.wav            NaN          NaN  \n",
       "1                                        NaN       1.122022          7.0  \n",
       "2                                        NaN            NaN          NaN  \n",
       "3    stimuli/di4-hN_48000Hz_pol2_S15filt.wav            NaN          NaN  \n",
       "4                                        NaN       0.717730          2.0  \n",
       "..                                       ...            ...          ...  \n",
       "139                                      NaN       1.352762          1.0  \n",
       "140                                      NaN            NaN          NaN  \n",
       "141  stimuli/di3-iN_48000Hz_pol2_S15filt.wav            NaN          NaN  \n",
       "142                                      NaN       1.241594          1.0  \n",
       "143                                      NaN            NaN          NaN  \n",
       "\n",
       "[144 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a56762c1-0345-472a-9f6f-2c783ab6ce3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      sound\n",
       "1       resp\n",
       "2         fb\n",
       "3      sound\n",
       "4       resp\n",
       "       ...  \n",
       "139     resp\n",
       "140       fb\n",
       "141    sound\n",
       "142     resp\n",
       "143       fb\n",
       "Name: 0, Length: 144, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bids_df.trial_type.str.split('_', expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5fc5ca-232b-49d4-8392-b950ffc84443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
